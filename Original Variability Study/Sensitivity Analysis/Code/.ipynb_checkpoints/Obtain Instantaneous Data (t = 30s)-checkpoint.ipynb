{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38eef577",
   "metadata": {},
   "source": [
    "# This script uses the starting points of the weather sonde trajectories to pinpoint the instantaneous profiles associated with each trajectory starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb90c23d",
   "metadata": {},
   "source": [
    " ## Preliminary Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d5a1779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot import USCOUNTIES and USSTATES without Cartopy installed.\n"
     ]
    }
   ],
   "source": [
    "#Import Packages\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import metpy \n",
    "import metpy.calc as mpcalc\n",
    "from metpy.plots import SkewT\n",
    "from metpy.units import units \n",
    "from IPython.display import HTML, display \n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "from itertools import product \n",
    "import wrf\n",
    "import glob \n",
    "from scipy.interpolate import RegularGridInterpolator, interp1d\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c3fd364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Path For Data Collection and Create A List of File Names\n",
    "storm16_data_path = '/storage/work/bsh5393/storm16/'\n",
    "storm16_files = os.listdir(storm16_data_path)\n",
    "\n",
    "#Remove Unneccessary Files From Storm 16 File List\n",
    "storm16_files.remove('README-TIMELEVELS')\n",
    "storm16_files.remove('namelist.input')\n",
    "storm16_files.remove('runstorm16.pbs.o44255112')\n",
    "storm16_files.remove('cm1out_stats.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f761375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Initialization and Input Parameters\n",
    "\n",
    "#Data at t = 2hrs\n",
    "storm_data = xr.open_dataset(storm16_data_path + storm16_files[-1])\n",
    "\n",
    "#Dataset Domain Size\n",
    "ni = storm_data['ni']\n",
    "nj = storm_data['nj']\n",
    "nk = storm_data['nk']\n",
    "\n",
    "#Datapoint Locations\n",
    "x_data = storm_data['xh']*units.kilometer\n",
    "y_data = storm_data['yh']*units.kilometer\n",
    "z_data = storm_data['z']*units.kilometer\n",
    "\n",
    "#Grid Locations (n+1)\n",
    "x_grid = storm_data['xf']*units.kilometer\n",
    "y_grid = storm_data['yf']*units.kilometer\n",
    "z_grid = storm_data['zf']*units.kilometer\n",
    "\n",
    "#Create New Lower/Upper Bound Variables Since We are not in the center of the domain anymore\n",
    "lower_bound_x = np.abs(x_data.values - (x_data[-1].values-25)).argmin()-2\n",
    "upper_bound_x = np.abs(x_data.values - x_data[-1].values).argmin()\n",
    "lower_bound_y = np.abs(y_data.values - 5).argmin()\n",
    "upper_bound_y = np.abs(y_data.values - 30).argmin()+2\n",
    "horiz_length = upper_bound_y-lower_bound_y\n",
    "\n",
    "#Grid Size \n",
    "size_x = size_y = upper_bound_x-lower_bound_x\n",
    "size_z = len(z_data)\n",
    "\n",
    "#Grid Spacing \n",
    "dx = x_data[1].values - x_data[0].values\n",
    "dy = y_data[1].values - y_data[0].values\n",
    "dz = np.zeros(len(z_data))\n",
    "dz[0] = z_data[0].values\n",
    "dz[1:] = z_data[1:].values-z_data[0:-1].values\n",
    "\n",
    "#Time Intervals of Data\n",
    "time = []\n",
    "for x in np.arange(1,len(storm16_files),1):\n",
    "    t = xr.open_dataset(storm16_data_path + storm16_files[x])['time']\n",
    "    time.append(t)    \n",
    "time = (np.asarray(time)*10**-9).reshape(len(time))\n",
    "time = time.astype('int')\n",
    "time = time - time[0]+30 #time elapsed in seconds (useful for interpolation later on)\n",
    "\n",
    "#Time Intervals of Interpolation (We want every 10 seconds)\n",
    "int_time = np.arange(int(time[0]), int(time[-1]), 10)\n",
    "nanal = len(int_time) #Number of Trajectory Points \n",
    "dt = int_time[1]-int_time[0]\n",
    "\n",
    "#Input Parameters \n",
    "asc_rate = 5 #3 m/s ascent rate of balloon\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a158eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute Temperature from pressure and potential temperature using adiabatic relationship\n",
    "def comp_T_from_Th(pressure, pot_temperature):\n",
    "    P_0 = 100000\n",
    "    R_d = 287 #J/(kg*K)\n",
    "    c_p = 1004 #J/(kg*K)\n",
    "    K = R_d/c_p\n",
    "    T = pot_temperature*(P_0/pressure)**(-K)\n",
    "    \n",
    "    return T;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d946ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute Dewpoint Temperature from pressure, temperature, and specific humidity\n",
    "def comp_dewpoint(pressure, temperature, specific_humidity):\n",
    "    \n",
    "    q = specific_humidity\n",
    "    eps = 0.622\n",
    "    \n",
    "    #mixing ratio\n",
    "    w = q/(1-q)\n",
    "    \n",
    "    #vapor pressure (in Pa converted to mb)\n",
    "    e = 0.01*(pressure*w)/(eps+w)\n",
    "    \n",
    "    #Dewpoint from Bolton 1980\n",
    "    T = (243.5*np.log(e/6.112))/(17.67-np.log(e/6.112))+273.15\n",
    "    \n",
    "    return T;\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d92fd9c",
   "metadata": {},
   "source": [
    "## The Good Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb4f493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Points From Trajectories\n",
    "path = '/storage/work/bsh5393/Variability Study/Sensitivity Analysis/Data/'\n",
    "\n",
    "traj_points = np.load(path+'interpolation_2_rawtrajectories.npz')['interp_points']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "325a9929",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112225/112225 [00:01<00:00, 90988.81it/s]\n"
     ]
    }
   ],
   "source": [
    "#We need to find the index nearest for each trajectory starting point to pinpoint the instaneous profile\n",
    "\n",
    "#Grid Values\n",
    "x = x_data.values\n",
    "y = y_data.values\n",
    "z = z_data.values\n",
    "\n",
    "\n",
    "#Format of nearest index: sz,sy,sx\n",
    "#Create Index Storage\n",
    "inst_ind = np.zeros((traj_points[0].shape), dtype = int)\n",
    "\n",
    "#Create A Loop That Finds Nearest Index For Every Starting Point\n",
    "for i in tqdm(np.arange(0, (traj_points[0]).shape[0],1)):\n",
    "    # separate the x, y, z coordinates\n",
    "    xp = traj_points[0][i,2]\n",
    "    yp = traj_points[0][i,1]\n",
    "    zp = traj_points[0][i,0]\n",
    "    \n",
    "    # grabs the closest CM1 gridpoint\n",
    "    sx = np.searchsorted(x, xp)\n",
    "    sy = np.searchsorted(y, yp)\n",
    "    sz = np.searchsorted(z, zp) - 1\n",
    "    \n",
    "    # recombine\n",
    "    inst_ind[i] = sz,sy,sx\n",
    "    \n",
    "\n",
    "# Max and Min Of Each Index Range\n",
    "z_min = inst_ind[:,0].min()\n",
    "z_max = inst_ind[:,0].max()\n",
    "y_min = inst_ind[:,1].min()\n",
    "y_max = inst_ind[:,1].max()\n",
    "x_min = inst_ind[:,2].min()\n",
    "x_max = inst_ind[:,2].max()\n",
    "\n",
    "# Shift Inst_Ind Array (this is needed because in the following cell, once the slice function \n",
    "# is used to grab a subset of the netCDF, it reorders all the indices such that the lowest x and y index is \n",
    "# now 0, which means we now need to shift our indices downward as well, so we're grabbing the right profile \n",
    "# for the right starting point)  \n",
    "inst_ind[:,0] = inst_ind[:,0] - z_min\n",
    "inst_ind[:,1] = inst_ind[:,1] - y_min\n",
    "inst_ind[:,2] = inst_ind[:,2] - x_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29d896b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantaneous Data From Model Output (t = 30s : start of weather sonde lifting)\n",
    "#Trim the Data We Are Bringing in Based on index range to cut down computation time\n",
    "inst_storm_data = xr.open_dataset(storm16_data_path + storm16_files[1])[['prs','th','qv','uinterp','vinterp','winterp','zvort']].isel(time=0, nj=slice(y_min, y_max+1), ni=slice(x_min, x_max+1))\n",
    "\n",
    "#Decomposing Preemptively into arrays to save additional time\n",
    "P_data = inst_storm_data['prs'].values\n",
    "Th_data = inst_storm_data['th'].values\n",
    "qv_data = inst_storm_data['qv'].values\n",
    "u_data = inst_storm_data['uinterp'].values\n",
    "v_data = inst_storm_data['vinterp'].values\n",
    "w_data = inst_storm_data['winterp'].values\n",
    "zvort_data = inst_storm_data['zvort'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad4854a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112225/112225 [00:01<00:00, 78087.75it/s]\n"
     ]
    }
   ],
   "source": [
    "#Create A Loop That Saves Instantaneous Vertical Data For Each Starting Trajectory Point\n",
    "#Essentially just reshaping the DataArray where the orginal data is\n",
    "\n",
    "#Create Storage Arrays\n",
    "P = np.zeros((121,112225))\n",
    "Th = np.zeros((121,112225))\n",
    "qv = np.zeros((121,112225))\n",
    "u = np.zeros((121,112225))\n",
    "v = np.zeros((121,112225))\n",
    "w = np.zeros((121,112225))\n",
    "zvort = np.zeros((121,112225))\n",
    "\n",
    "for i in tqdm(np.arange(0,traj_points.shape[1],1)):\n",
    "    #Decompose Indices Array\n",
    "    sy = inst_ind[i,1]\n",
    "    sx = inst_ind[i,2]\n",
    "    \n",
    "    #Grab Appropriate Vertical Column\n",
    "    P[:,i] = P_data[:,sy,sx]\n",
    "    Th[:,i] = Th_data[:,sy,sx]\n",
    "    qv[:,i] = qv_data[:,sy,sx]\n",
    "    u[:,i] = u_data[:,sy,sx]\n",
    "    v[:,i] = v_data[:,sy,sx]\n",
    "    w[:,i] = w_data[:,sy,sx]\n",
    "    zvort[:,i] = zvort_data[:,sy,sx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1636d889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112225/112225 [00:02<00:00, 38071.27it/s]\n"
     ]
    }
   ],
   "source": [
    "#Now Let's Work on Doing Calculations To Create Soundings (Only Run Once)\n",
    "\n",
    "#Create New Variables\n",
    "\n",
    "T = np.zeros(P.shape)\n",
    "Td = np.zeros(P.shape)\n",
    "\n",
    "#I personally don't like metpy for the calculations. I'm going to create two functions that do metpy things better.\n",
    "for i in tqdm(np.arange(0,P.shape[1],1)):\n",
    "    T[:,i] = comp_T_from_Th(P[:,i], Th[:,i])\n",
    "    Td[:,i] = comp_dewpoint(P[:,i], T[:,i], qv[:,i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f178756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112225/112225 [2:14:22<00:00, 13.92it/s] \n"
     ]
    }
   ],
   "source": [
    "#Compute Parcel Profile\n",
    "parcel_prof = np.zeros(P.shape)\n",
    "\n",
    "for i in tqdm(np.arange(0,P.shape[1], 1)):\n",
    "    parcel_prof[:,i] = (metpy.calc.parcel_profile(P[:,i]*units.Pa, (T[:,i]*units.kelvin)[0], (Td[:,i]*units.kelvin)[0])).magnitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22747978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save The Data Calculated So Far (Need to do CAPE,CIN,SRH1km, SRH3km)\n",
    "\n",
    "path = '/storage/work/bsh5393/Variability Study/Sensitivity Analysis/Data/'\n",
    "\n",
    "np.savez(path+'instantaneous_data', P = P, T = T, Td = Td, Th = Th, qv = qv, u = u , v = v, w = w, zvort = zvort, parc_T = parcel_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77257923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interp_points\n",
      "P\n",
      "T\n",
      "Td\n",
      "Th\n",
      "qv\n",
      "u\n",
      "v\n",
      "w\n",
      "zvort\n",
      "parc_T\n",
      "CAPE\n",
      "CIN\n",
      "SRH1km\n",
      "SRH3km\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/bsh5393/new/lib64/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: NpzFile.iterkeys is deprecated in python 3, to match the removal of dict.iterkeys. Use .keys() instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#Check Data in .npz file\n",
    "path = '/storage/work/bsh5393/Variability Study/Sensitivity Analysis/Data/'\n",
    "x = np.load(path+'instantaneous_data.npz')\n",
    "for k in x.iterkeys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78228cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in Saved Data \n",
    "path = '/storage/work/bsh5393/Variability Study/Sensitivity Analysis/Data/'\n",
    "\n",
    "data = np.load(path+'instantaneous_data.npz')\n",
    "\n",
    "P = data['P']\n",
    "T = data['T']\n",
    "Td = data['Td']\n",
    "Th = data['Th']\n",
    "qv = data['qv']\n",
    "u = data['u']\n",
    "v = data['v']\n",
    "w = data['w']\n",
    "zvort = data['zvort']\n",
    "parc_T = data['parc_T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cc7aa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112225/112225 [20:13<00:00, 92.44it/s]\n"
     ]
    }
   ],
   "source": [
    "#Calculate CAPE, CIN, SRH1km, SRH3km\n",
    "\n",
    "CAPE = np.zeros(P.shape)\n",
    "CIN = np.zeros(P.shape)\n",
    "SRH1km = np.zeros(P.shape[1])\n",
    "SRH3km = np.zeros(P.shape[1])\n",
    "\n",
    "for n in tqdm(np.arange(0,P.shape[1], 1)):\n",
    "    #For the WRF CAPE Function We Need: Total Pressure (hPa), Temperature (degK), Water Vapor Mixing Ratio (kg/kg), *Geopotential Height* (m), Terrain Height (m), Surface Pressure (hPa)\n",
    "    results = wrf.cape_3d(P[:,n]/100, T[:,n], qv[:,n], z_data.values*1000, 0,P[0,n]/100,ter_follow = False,meta= False)\n",
    "    CAPE[:,n] = results[0][:,0,0]\n",
    "    CIN[:,n] = results[1][:,0,0]\n",
    "    SRH1km[n] = (mpcalc.storm_relative_helicity(z_data.values*units.km, u[:,n]*units('m/s'), v[:,n]*units('m/s'), depth = 1000*units('m')))[0].magnitude\n",
    "    SRH3km[n] = (mpcalc.storm_relative_helicity(z_data.values*units.km, u[:,n]*units('m/s'), v[:,n]*units('m/s'), depth = 3000*units('m')))[0].magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c81f4847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save The Data Calculated So Far (Need to do CAPE,CIN,SRH1km, SRH3km)\n",
    "\n",
    "path = '/storage/work/bsh5393/Variability Study/Sensitivity Analysis/Data/'\n",
    "\n",
    "np.savez(path+'instantaneous_data', interp_points = traj_points, P = P, T = T, Td = Td, Th = Th, qv = qv, u = u , v = v, w = w, zvort = zvort, parc_T = parc_T, CAPE = CAPE, CIN = CIN, SRH1km = SRH1km, SRH3km = SRH3km)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d3cb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
