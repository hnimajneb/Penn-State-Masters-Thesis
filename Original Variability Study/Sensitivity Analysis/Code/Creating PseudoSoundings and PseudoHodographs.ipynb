{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a5818c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot import USCOUNTIES and USSTATES without Cartopy installed.\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import metpy\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.plots import SkewT\n",
    "from metpy.units import units \n",
    "from IPython.display import HTML, display\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import wrf\n",
    "import glob\n",
    "from scipy.interpolate import RegularGridInterpolator, interp1d\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import TwoSlopeNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa6b2332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Path For Data Collection and Create A List of File Names\n",
    "storm16_data_path = '/storage/work/bsh5393/storm16/'\n",
    "storm16_files = os.listdir(storm16_data_path)\n",
    "\n",
    "#Remove Unneccessary Files From Storm 16 File List\n",
    "storm16_files.remove('README-TIMELEVELS')\n",
    "storm16_files.remove('namelist.input')\n",
    "storm16_files.remove('runstorm16.pbs.o44255112')\n",
    "storm16_files.remove('cm1out_stats.nc')\n",
    "\n",
    "#Read in Raw Trajectories\n",
    "\n",
    "#Step 1: Initialization and Input Parameters\n",
    "\n",
    "#Data at t = 2hrs\n",
    "storm_data = xr.open_dataset(storm16_data_path + storm16_files[-1])\n",
    "\n",
    "#Dataset Domain Size\n",
    "ni = storm_data['ni']\n",
    "nj = storm_data['nj']\n",
    "nk = storm_data['nk']\n",
    "\n",
    "#Datapoint Locations\n",
    "x_data = storm_data['xh']*units.kilometer\n",
    "y_data = storm_data['yh']*units.kilometer\n",
    "z_data = storm_data['z']*units.kilometer\n",
    "\n",
    "#Grid Locations (n+1)\n",
    "x_grid = storm_data['xf']*units.kilometer\n",
    "y_grid = storm_data['yf']*units.kilometer\n",
    "z_grid = storm_data['zf']*units.kilometer\n",
    "\n",
    "#Create New Lower/Upper Bound Variables Since We are not in the center of the domain anymore\n",
    "lower_bound_x = np.abs(x_data.values - (x_data[-1].values-25)).argmin()-2\n",
    "upper_bound_x = np.abs(x_data.values - x_data[-1].values).argmin()\n",
    "lower_bound_y = np.abs(y_data.values - 5).argmin()\n",
    "upper_bound_y = np.abs(y_data.values - 30).argmin()+2\n",
    "horiz_length = upper_bound_y-lower_bound_y\n",
    "\n",
    "#Grid Size \n",
    "size_x = size_y = upper_bound_x-lower_bound_x\n",
    "size_z = len(z_data)\n",
    "\n",
    "#Grid Spacing \n",
    "dx = x_data[1].values - x_data[0].values\n",
    "dy = y_data[1].values - y_data[0].values\n",
    "dz = np.zeros(len(z_data))\n",
    "dz[0] = z_data[0].values\n",
    "dz[1:] = z_data[1:].values-z_data[0:-1].values\n",
    "\n",
    "#Time Intervals of Data\n",
    "time = []\n",
    "for x in np.arange(1,len(storm16_files),1):\n",
    "    t = xr.open_dataset(storm16_data_path + storm16_files[x])['time']\n",
    "    time.append(t)    \n",
    "time = (np.asarray(time)*10**-9).reshape(len(time))\n",
    "time = time.astype('int')\n",
    "time = time - time[0]+30 #time elapsed in seconds (useful for interpolation later on)\n",
    "\n",
    "#Time Intervals of Interpolation (We want every 10 seconds)\n",
    "int_time = np.arange(int(time[0]), int(time[-1]), 10)\n",
    "nanal = len(int_time) #Number of Trajectory Points \n",
    "dt = int_time[1]-int_time[0]\n",
    "\n",
    "#Input Parameters \n",
    "asc_rate = 5 #3 m/s ascent rate of balloon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbd04237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load The pseudo_data\n",
    "\n",
    "path = '/storage/work/bsh5393/Variability Study/Sensitivity Analysis/Data/'\n",
    "pseudo_data = np.load(path+'pseudodata_2_cm1grid.npz')\n",
    "points_data = np.load(path+'instantaneous_data.npz')\n",
    "\n",
    "\n",
    "#Data Interpolated to Model Grid\n",
    "P = pseudo_data['P']\n",
    "T = pseudo_data['T']\n",
    "Th = pseudo_data['Th']\n",
    "Td = pseudo_data['Td']\n",
    "qv = pseudo_data['qv']\n",
    "u = pseudo_data['u']\n",
    "v = pseudo_data['v']\n",
    "w = pseudo_data['w']\n",
    "zvort = pseudo_data['zvort']\n",
    "parc_T = pseudo_data['parc_T']\n",
    "CAPE = pseudo_data['CAPE']\n",
    "CIN = pseudo_data['CIN']\n",
    "SRH1km = pseudo_data['SRH1km']\n",
    "SRH3km = pseudo_data['SRH3km']\n",
    "\n",
    "#Original Trajectory Points\n",
    "# points = pseudo_data['interp_points']\n",
    "\n",
    "#Ground Relative Winds\n",
    "offset_u = 12.2 \n",
    "offset_v = 12.5 \n",
    "gr_u = u[0] + offset_u\n",
    "gr_v = v[0] + offset_v\n",
    "gr_wind = np.sqrt((gr_u**2)+(gr_v**2)) \n",
    "\n",
    "inst_data = np.load(path+'instantaneous_data.npz')\n",
    "points_data = np.load(path+'interpolation_2_rawtrajectories.npz')\n",
    "\n",
    "inst_P = inst_data['P']\n",
    "inst_T = inst_data['T']\n",
    "inst_Td = inst_data['Td']\n",
    "inst_Th = inst_data['Th']\n",
    "inst_qv = inst_data['qv']\n",
    "inst_u = inst_data['u']\n",
    "inst_v = inst_data['v']\n",
    "inst_w = inst_data['w']\n",
    "inst_zvort = inst_data['zvort']\n",
    "inst_parc_T = inst_data['parc_T']\n",
    "inst_CAPE = inst_data['CAPE']\n",
    "inst_CIN = inst_data['CIN']\n",
    "inst_SRH1km = inst_data['SRH1km']\n",
    "inst_SRH3km = inst_data['SRH3km']\n",
    "\n",
    "#Original Trajectory Points\n",
    "points = points_data['interp_points']\n",
    "\n",
    "#Ground Relative Winds\n",
    "offset_u = 12.2\n",
    "offset_v = 12.5 \n",
    "gr_u = inst_u[0]+offset_u\n",
    "gr_v = inst_v[0]+offset_v\n",
    "inst_gr_wind = np.sqrt((gr_u**2)+(gr_v**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76655599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:26<00:00,  3.76it/s]\n"
     ]
    }
   ],
   "source": [
    "#Try to Plot Multiple (Tweak This To Pick 100 Random Soundings)\n",
    "\n",
    "path = '/storage/work/bsh5393/Variability Study/Sensitivity Analysis/Figure Builder/'\n",
    "gifname = '/storage/work/bsh5393/Variability Study/Sensitivity Analysis/GIFs/100randpseudosoundings.gif'\n",
    "\n",
    "\n",
    "for x in tqdm(range(100)):\n",
    "    \n",
    "    k = np.random.randint(0,335**2)\n",
    "    image_filename = \"figure_%03d.png\" % (x)\n",
    "    # Plot the data using normal plotting functions, in this case using\n",
    "    # log scaling in Y, as dictated by the typical meteorological plot.\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    skew = SkewT(fig, rotation=45)\n",
    "    skew.ax.set_ylim(1000, 100)\n",
    "    skew.ax.set_xlim(-40, 60)\n",
    "    skew.plot(P[:,k]*units.Pa, T[:,k]*units.kelvin, 'r')\n",
    "    skew.plot(P[:,k]*units.Pa, Td[:,k]*units.kelvin, 'r')\n",
    "    skew.plot_barbs(P[:,k]*units.Pa, u[:,k]*units('m/s'), v[:,k]*units('m/s'))\n",
    "\n",
    "    # Set some better labels than the default\n",
    "    skew.ax.set_title(f'100 Random PseudoSoundings (ID: {k})')\n",
    "    skew.ax.set_xlabel(f'Temperature ({(T[:,k]*units.kelvin).units:~P})')\n",
    "    skew.ax.set_ylabel(f'Pressure ({(P[:,k]*units.Pa).units:~P})')\n",
    "\n",
    "    # Calculate full parcel profile and add to plot as black line\n",
    "    #prof = mpcalc.parc_T(p_avg, T_avg[0], Td_avg[0]).to('degC')\n",
    "    skew.plot(P[:,k]*units.Pa, parc_T[:,k]*units.kelvin, 'r--', linewidth=2)\n",
    "\n",
    "    # Add the relevant special lines\n",
    "    #skew.plot_dry_adiabats()\n",
    "    #skew.plot_moist_adiabats()\n",
    "    #skew.plot_mixing_lines()\n",
    "\n",
    "    #Relative Storm Motion \n",
    "    offset_u = 12.2*units.meter_per_second\n",
    "    offset_v = 12.5*units.meter_per_second\n",
    "    #Add Hodograph\n",
    "    ax_hodograph = fig.add_axes([.84, 0.7, 0.18, 0.18])\n",
    "    h = metpy.plots.Hodograph(ax_hodograph, component_range=40.)\n",
    "    h.add_grid(increment=5)\n",
    "    h.plot(u[:, k] * units('m/s')+offset_u, v[:, k] * units('m/s')+offset_v, color='tab:red')\n",
    "    \n",
    "    #Save the figure\n",
    "    fig.savefig(path + image_filename)\n",
    "    \n",
    "    #clear the figure\n",
    "    plt.close()\n",
    "\n",
    "#These variables control the time step (interval) and the length of the pause at the end of the animation (end_interval)\n",
    "interval = 0.25\n",
    "end_interval = 1.0\n",
    "\n",
    "#Iterating through all of the files in path, and then sorting the filenames\n",
    "imagefiles = os.listdir(path)\n",
    "imagefiles.remove('.ipynb_checkpoints')\n",
    "\n",
    "\n",
    "image_filenames = []\n",
    "\n",
    "for image_filename in imagefiles[:x]:\n",
    "    image_filenames.append(image_filename)\n",
    "image_filenames.sort()\n",
    "    \n",
    "#Opening each image file and saving it to a list\n",
    "images = []\n",
    "for image_filename in image_filenames[:x]:\n",
    "    images.append(imageio.imread(path + image_filename))\n",
    "      \n",
    "#Generating an array containing the duration to display each frame\n",
    "durations = np.ones(len(images))*interval\n",
    "durations[-1] = end_interval\n",
    "\n",
    "#Generating the animation itself\n",
    "imageio.mimsave(gifname, images, duration = durations.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec7ae872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:28<00:00,  3.54it/s]\n"
     ]
    }
   ],
   "source": [
    "#Create A GIF That Randomly Selects 100 Pseudo & Instantanous \n",
    "\n",
    "path = '/storage/work/bsh5393/Variability Study/Sensitivity Analysis/Figure Builder/'\n",
    "gifname = '/storage/work/bsh5393/Variability Study/Sensitivity Analysis/GIFs/100randsoundingscompared.gif'\n",
    "\n",
    "for x in tqdm(range(100)):\n",
    "    #Choose Random Sounding ID \n",
    "    k = np.random.randint(0,P.shape[1])\n",
    "    image_filename = \"figure_%03d.png\" % (x)\n",
    "    \n",
    "    #figure initialization\n",
    "    fig = plt.figure(figsize = (15,10))\n",
    "    skew = SkewT(fig, rotation = 45)\n",
    "    \n",
    "    \n",
    "    #PSEUDO\n",
    "    skew.plot(P[:,k]*units.Pa, T[:,k]*units.degK, 'g')\n",
    "    skew.plot(P[:,k]*units.Pa, Td[:,k]*units.degK, 'g')\n",
    "    skew.plot(P[:,k]*units.Pa, parc_T[:,k]*units.kelvin, 'g.', linewidth=2)\n",
    "    #skew.plot_barbs(P[:,k]*units.Pa, u[:,k]*units('m/s'), v[:,k]*units('m/s'))\n",
    "    skew.ax.set_ylim(1000,100)\n",
    "    skew.ax.set_xlim(-40,60)\n",
    "    \n",
    "    #cosmetics\n",
    "    skew.ax.set_title(f'100 Randomly Selected Pseudo (g) vs. Instantaneous (r) Soundings (ID: {k})')\n",
    "    skew.ax.set_xlabel(f'Temperature ({(T[:,k]*units.kelvin).units:~P})')\n",
    "    skew.ax.set_ylabel(f'Pressure ({(P[:,k]*units.Pa).units:~P})')\n",
    "    \n",
    "    #INSTANTANEOUS\n",
    "    skew.plot(inst_P[:,k]*units.Pa, inst_T[:,k]*units.degK, 'r')\n",
    "    skew.plot(inst_P[:,k]*units.Pa, inst_Td[:,k]*units.degK, 'r')\n",
    "    skew.plot(inst_P[:,k]*units.Pa, inst_parc_T[:,k]*units.kelvin, 'r--', linewidth=2)\n",
    "    #skew.plot_barbs(inst_P[:,k]*units.Pa, inst_u[:,k]*units('m/s'), inst_v[:,k]*units('m/s'))\n",
    "    skew.ax.set_ylim(1000,100)\n",
    "    skew.ax.set_xlim(-40,60)\n",
    "    \n",
    "    #cosmetics\n",
    "    skew.ax.set_xlabel(f'Temperature ({(inst_T[:,k]*units.kelvin).units:~P})')\n",
    "    skew.ax.set_ylabel(f'Pressure ({(inst_P[:,k]*units.Pa).units:~P})')\n",
    "    \n",
    "    #Plot Hodographs \n",
    "    ax_hodograph = fig.add_axes([.84, 0.7, 0.18, 0.18])\n",
    "    h = metpy.plots.Hodograph(ax_hodograph, component_range = 40.)\n",
    "    h.add_grid(increment = 5)\n",
    "    h.plot(inst_u[:,k]+offset_u, inst_v[:,k]+offset_v, color='tab:green')\n",
    "    h.plot(u[:,k]+offset_u, v[:,k]+offset_v, color='tab:red')\n",
    "    \n",
    "    #Save Figure\n",
    "    fig.savefig(path+image_filename)\n",
    "    \n",
    "    #Clear Figure \n",
    "    plt.close()\n",
    "    \n",
    "    #Combine Above Images into GIF\n",
    "#These variables control the time step (interval) and the length of the pause at the end of the animation (end_interval)\n",
    "interval = 0.35\n",
    "end_interval = 1.0\n",
    "\n",
    "#Iterating through all of the files in path, and then sorting the filenames\n",
    "imagefiles = os.listdir(path)\n",
    "imagefiles.remove('.ipynb_checkpoints')\n",
    "\n",
    "\n",
    "image_filenames = []\n",
    "\n",
    "for image_filename in imagefiles[:x]:\n",
    "    image_filenames.append(image_filename)\n",
    "image_filenames.sort()\n",
    "    \n",
    "#Opening each image file and saving it to a list\n",
    "images = []\n",
    "for image_filename in image_filenames[:x]:\n",
    "    images.append(imageio.imread(path + image_filename))\n",
    "      \n",
    "#Generating an array containing the duration to display each frame\n",
    "durations = np.ones(len(images))*interval\n",
    "durations[-1] = end_interval\n",
    "\n",
    "#Generating the animation itself\n",
    "imageio.mimsave(gifname, images, duration = durations.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39c38e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
